##### up:: [DAYS](../mocs/days.md)

##### next:: [Saturday](./30Sept2023.md)

##### previous:: [Thursday](./28Sept2023.md)

# Friday

# 07:38

- Just started my laptop up

- Have a lot of quick adjustments to make based off my ruminations

# 07:42

- Updated the [AGILE](../documents/agile.md) document with some things I forgot yesterday

- Added the [Design Rules](../documents/functional_breakdown/design_rules.md)

# 08:06

- Just finished up with these changes

# 08:11

- Started setting up the kanban board

# 08:26

- Got the board setup and link sharing working

- Just going to populate it real quick

# 09:00

- Just finished up

- Will come back later to start building the program

# 10:36

- Starting a bit early today 

# 10:52

- I am currently assessing the log file structure and semantics

# 11:02

- The log file is really massive, but contains a lot of duplicate records with different times. I'm assuming this is whenever an inference is being called on a camera based on the rules defined by the user

- I'm considering writting a program to seperate all the unique calls to make it a bit easier to understand all the information contained in the log file

- But first I'm just trying to document query the files through a really cool, free AI LLM site ([h20GPT](https://gpt.h2o.ai)) ,with some of the best open source models currently and gpt-3.5

# 11:14

- Got really great insights from h20GPT. [h20GPT github](https://github.com/h2oai/h2ogpt), as detailed here in [Log Structure Analysis](../documents/functional_breakdown/log_structure_analysis.md)

# 11:27

- Broke down all the tasks for log parsing on the [Kanban](https://tree.taiga.io/project/jayfalls-log-analyser)

- Created [Log Structure Analysis](../documents/functional_breakdown/log_structure_analysis.md)

# 11:39

- I am now finally starting to build the program, HOORAH! I could not wait to start

- I have broken down, and will continue to as needed, the steps of parsing the log file into its smallest constituites over on the [Kanban](https://tree.taiga.io/project/jayfalls-log-analyser)

# 11:52

- I am currently writting code to load the log file and remove all of the lines where the type is [REPORTING], as I see these are just function calls, they might be relevant for later use cases, but from what I can tell it should not be relevant under the current context. I'll keep my eye open to see if maybe this is a mistake.

- To write this code I'm using h20

# 12:32

- Made the log loader and cleaner an asyncronous function

- Mad a syncronous version out of curiosity, which led me to make speed tests
  
  - Probably not the best use of time, but yeah it's confirmed, the asyncronous version is an order of magnitude faster. Cool

# 12:37

- Heading out to my girlfriend to continue work at her place

# 13:24

- Just ate and got settled

- About to start on the next tasks on the [Kanban](https://tree.taiga.io/project/jayfalls-log-analyser)

# 13:34

- I am busy implementing a sqlite database to write to
  
  - I'm not a sql expert, so I'm relying on the gpt to help me figure out concepts and best practices

# 14:08

- Had some issues with internet, fixed it now

- Got the function to initialise the database working

# 14:48

- Got the function to seperate all the different items in a line into their own variables

- This was relatively easy, just a bunch of trial and error

- I've been using gpt as a crutch here a lot, I could figure it all out myself, but I find it quicker to just let the ai problem solve and code this simple tasks for me, and I just correct and finetune the code to fit and work properly

# 14:58

- Taking a quick break

# 15:10

- Started work on writing out to the database

# 15:22

- I'm doing a lot of small refactors to the code, trying to remove repetition as much as is reasonable, making the code more maintainable

# 15:38

- Just got writing to the database working, and it all seems to be going well. This was pretty brainless

- Fixing an edge case of entering duplicate data

# 15:51

- Just finished log parsing, feels good
  
  - Took me so long because I was just debugging things like incorrect sql queries and refactoring

- Going to write some tests now

# 16:01

- Tests are so boring damn, but they are necessary

- I just used gpt-3.5 to generate a list of tests for normal use and edgecases, and then used that output to generate a list of tests in code

- Going to use pytest

- Now I will copy over the code and make sure everything is functioning as expected after taking a short break

# 16:20

- So I noticed that because I just plugged in the code and all of the tests I'd like written, and had gpt3.5 write it all out at once, I don't understand the code and reasoning, so I'd just be copying a ton of code hoping it'll work, **YIKES**

- As such, I will shift my approach to prompting gpt3.5 with all the code, and asking it for each function to first adapt the code for edge cases, and then to write a test
  
  - This way I'll still go through each adaptation and test case myself, allowing me to understand the code

# 17:07

- Just finished adding all the error checking to the code
  
  - Mostly just copy pasting from gpt3.5, then making slight adjustments as needed

# 17:28

- Just finished cleaning up the code.

- Added [Future Considerations](../sentiments/future_considerations.md)

- I've run out of time for today, will have to finish with my spillover time tomorrow