##### up:: [DAYS](../mocs/days.md)

##### previous:: [Monday](./02Oct2023.md)

##### next:: [Wednesday](./04Oct2023.md)

# Tuesday

# 06:51

- Good Morning new day!

- I've decided that today, I'm just going to start off by learning.
  
  - If I had done this as part of my planning, I probably would've saved a day or two. But you live and learn
  
  - I usually use youtube videos as my main learning tool, with google and chatting with an ai with further questions as supplements to that
  
  - The reason I *SKIPPED* the learning is because I assumed that the solution wouldn't be on youtube, and that I'd have to figure it out myself. I almost **ALWAYS** use youtube when I'm approached with unfamiliar concepts.
  
  - This way I get to learn and understand the concepts within my own framing, not just copy pasta like I did yesterday

# 07:01

- So a quick check on patterns and I'm finding all these great videos:
  
  - [Fundamentals of Data Science with Python: Finding Patterns with Descriptive Statistics](https://www.youtube.com/watch?v=VohdcwGLVnw)
  
  - [Finding Patterns & Outcomes w/ Time Series Data](https://www.youtube.com/watch?v=zBVQvVCZPCM)
  
  - [Automatically Find Patterns & Anomalies from Time Series or Sequential Data](https://www.youtube.com/watch?v=WvaBPSeA_JA)

- And in searching for those videos, I found these great Python playlists that will elevate my python skills for sure(gonna go through these when I'm done with this project):
  
  - [Software Design in Python](https://www.youtube.com/playlist?list=PLC0nd42SBTaNuP4iB4L6SJlMaHE71FG6N)
  
  - [Architecture & Cloud](https://youtube.com/playlist?list=PLC0nd42SBTaO3aajVi2FomC86q6TeRM_Y&si=JtQFm571HKe8mcwa)
  
  - [Software Testing](https://youtube.com/playlist?list=PLC0nd42SBTaPYSgBqtlltw328zuafaCzA&si=h_5yRqswOlhVbZTp)
  
  - Yes these playlists are all from the same guy, but I've seen his videos before and I like his way of sharing knowledge as well as him being a python expert, so I know I'll get value from all these playlists

# 07:07

- I'm going to start with the pattern videos and see if I can get it implemented.

# 07:17

- So as I was starting this video: 
  [Fundamentals of Data Science with Python: Finding Patterns with Descriptive Statistics](https://www.youtube.com/watch?v=VohdcwGLVnw), I noticed it's a whole playlist of really short videos:
  [Fundamentals of Data Science with Python](https://www.youtube.com/playlist?list=PLTgRMOcmRb3MHWbS838mwbNqGGEgbmym8)
  
  - I'm going to go through the whole playlist to get a high level overview
  
  - And then this similiar playlist from the same channel:
    [Time Series Analysis with Python](https://www.youtube.com/playlist?list=PLTgRMOcmRb3MpykLdyTwi9B1tLU9_KdEF)

# 07:26

- Deleting all my work from yesterday

# 07:31

- So starting off with this playlist: [Fundamentals of Data Science with Python](https://www.youtube.com/playlist?list=PLTgRMOcmRb3MHWbS838mwbNqGGEgbmym8), I'm being introduced to numpy

- Multi-dimensional arrays, **cool**, but maybe a bit overkill for what I need, just going to keep going, because it's definitely a good intro for me as someone who knows basically nothing of data science

# 07:43

- Now getting into matplotlib

- I usually do things like this, learn from videos and then apply my knowledge
  
  - I guess because I was trying to be smart and skip this learning process, but it just ended up making me look silly and wasting time
  
  - I'm definitely not making this mistake again

# 07:47

- I'm currently printing out my frequency of log types to the terminal. Going to quickly introduce a visualisation class and swap over to using a matplot bar graph instead of printing to terminal

# 08:08

- Created analysis_visualiser.py

- My database queries result in an output with lists of items as they are related to each other, but to plot as graphs they need to be seperate in a dimensional array

- As such I'm writting a function to do this in my AnalysisVisualiser class

# 08:42

- I have it implemented, but am having issues with my miniconda environment for some reason, *fun*

# 08:51

- Just deleted my miniconda install, it's working yay

- Gonna go back to studying now

# 08:56

- Fixed a bug where the frequencies werent ordered correctly

# 09:09

- I've moved onto learning time series data

- I'm noticing that I didn't convert the logs to proper datetime format when storing into the database, I'll have to fix this before I start

# 09:29

- Pandas is realy cool for structuring and sorting data

# 10:02

- Busy learning about non, weakly and stationary, time series data

- It's looking like weakly stationary is probably the best bet with the log data

# 10:07

- Moved onto learning from [Finding Patterns & Outcomes w/ Time Series Data](https://www.youtube.com/watch?v=zBVQvVCZPCM)

# 10:24

- So it's looking like one way I can approach this to to break everything down into averages, and then compare them with each other using [pearson correlation](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient)

- Moving on to [Automatically Find Patterns & Anomalies from Time Series or Sequential Data](https://www.youtube.com/watch?v=WvaBPSeA_JA)

# 10:36

- When it comes to drawing insights from data, the **CONTEXT** matters most. As such, there is ***NO ONE SOLUTION*** to every problem, and it needs to be deliberated and tested on an individual basis

- Simple solutions are more likely to be correct than more complex ones

# 10:53

- So what I got from [Automatically Find Patterns & Anomalies from Time Series or Sequential Data](https://www.youtube.com/watch?v=WvaBPSeA_JA) is:
  
  - The simplest approach is using euclidian distances(pythagoris) between a cluster of the data and the rest of the data to find a matrix map, we take the shortest distance for each of these matrix maps to form a matrix profile
  
  - This video details an open source library called [Stumpy](https://github.com/TDAmeritrade/stumpy) to handle this matrix profile calculation
  
  - Once you have the matrix profile, you can perform inferences on it

- I really like this approach, it's a general approach, simple, intuitive and most of the work is handled for me

- Now it's just to figure out exactly how I can use this data to do pattern and anomaly detection

# 11:07

- To understand exactly how I can achieve this I have found these two videos:
  
  - [Modern Time Series Analysis with STUMPY - Intro To Matrix Profiles](https://www.youtube.com/watch?v=T9_z7EpA8QM)
  
  - [Understanding the Behavior of Time Series Data Using the Matrix Profile](https://www.youtube.com/watch?v=6NAk4Jee3aE)

- I'm just going to take a quick break and get back to learning

# 11:37

- Just got back

- Going to jump into those two videos

# 12:21

- Fell asleep, didn't realise I'm this tired

- Going to go somewhere now, will be back soon

# 12:47

- Keep falling asleep

- I don't know whats going on today

- Gonna shut down and come back a bit later

# 13:42

- Just got started again

- In my office space, feeling good
  
  - Don't work in bed lol

# 13:44

- Going through this, [Understanding the Behavior of Time Series Data Using the Matrix Profile](https://www.youtube.com/watch?v=6NAk4Jee3aE), again. It's very informative, and helped me to rest really well, but now it's time to knock this out

# 14:04

- Okay I'm really starting to get it now

- So the way this matrix profile works, it is a concurrent stream to your time series data, that essentially plots out how similiar or different that section of the graph looks to itself in general. With peaks denoting a high difference to the average.
  
  - With this knowledge, a very easy way to do anomaly detection, is just to set thresholds on the data, as when the matrix profile is at a high value, the graph at that point looks more different than the rest of the points in the graph. Hopefully that gets the understanding across.

- This is really cool stuff. Taking in streams of data and trying to interept and make sense of it.

# 14:16

- I'm moving onto [Stumpy time series analysis](https://www.youtube.com/watch?v=akUeYkKBxpU) now

# 14:20

- I'm just going to spend some time getting the data from the database, and then loading it into DataFields with numpy and pandas

- I'm doing this to convert it to a timeseries graph so I can visualise everything

# 14:26

- So breaking this down, the [Design Document](../documents/design_document.md) wants these following things:
  - Identify patterns of recurring errors or warnings.
  - Determine if there are any temporal trends. For example, are certain errors more frequent at specific times of the day or on certain days of the week?
  - Check for any anomalies or unexpected spikes in log frequencies.
- To do this I can have multiple streams, I'll need to seperate each warning and error into its own plot, have two plots for all errors and all warnings throughout the day
- Once I have all these different streams, I'll need to find a way to compare them to produce the desired results

# 14:42

- Okay, so after analysing the database quickly, I've devised that the way I'm going to try and do this, is by doing a seperate time series graph for each unique error/stacktrace and unique error/stacktrace messages

- This is going to lead to a lot of seperate graphs, but I feel like this way the data will be a lot easier to manage and do something useful with. Plus I can easily merge them if need be

- The biggest downside I can see to this approach, is that it's going to take a lot of finetuning and learning about how the data interacts myself. I'm already so over my deadlines, but it's okay, I'm loving the new concepts

- Taking a short break

# 14:49

- Starting to build that function

# 15:56

- Just finished building the function to seperate all the unique messages into their own time series groups

# 16:12

- Shit, I'm realising this approach wont actually work, because there are no numerical values associated with just plain log messages

- I found this [Temporal analysis: Generating time series from events based data](https://www.youtube.com/watch?v=nU9m2BZczkI)

- Hopefully this will help me out, I'm really struggling right now lol

# 16:38

- **I need to change the database initialisation code to create table names based on the api-source-id**
  
  - This will create seperation of logs from several sources

- I'm just trying to figure out how to plot the data as time series

# 16:44

- I see that when it comes to this type of problem, there are many different manipulations to the data that you can do to tease out information, even combining multiple manipulations together into something new

- One of the ways I can think of interpreting this data as time series is:
  
  - **Break up the log into specified time segments, counting the frequency of errors in a given segment**
    
    - I think this has a lot of potential to yield results, and it's easily achievable within my current strengths
    
    - I can manipulate the time segments to get varying information

# 19:02

- Just got home

- About to try and implement what I suggested here earlier

# 19:21

- I just created the function to get all the messages with time seperated in a dictionary by log_type from the database

- Going to write a function to plot this out and render the graph

# 20:05

- Oh my word I actually got it working, **hallelujah**

- Now to figure out Stumpy and plot that out too